{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abbrev</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>al</td>\n",
       "      <td>01</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ak</td>\n",
       "      <td>02</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>az</td>\n",
       "      <td>03</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ar</td>\n",
       "      <td>04</td>\n",
       "      <td>Arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ca</td>\n",
       "      <td>05</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>co</td>\n",
       "      <td>06</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ct</td>\n",
       "      <td>07</td>\n",
       "      <td>Connecticut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>de</td>\n",
       "      <td>08</td>\n",
       "      <td>Delaware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dc</td>\n",
       "      <td>09</td>\n",
       "      <td>District of Columbia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fl</td>\n",
       "      <td>10</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ga</td>\n",
       "      <td>11</td>\n",
       "      <td>Georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hi</td>\n",
       "      <td>12</td>\n",
       "      <td>Hawaii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>id</td>\n",
       "      <td>13</td>\n",
       "      <td>Idaho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>il</td>\n",
       "      <td>14</td>\n",
       "      <td>Illinois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>in</td>\n",
       "      <td>15</td>\n",
       "      <td>Indiana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ia</td>\n",
       "      <td>16</td>\n",
       "      <td>Iowa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ks</td>\n",
       "      <td>17</td>\n",
       "      <td>Kansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ky</td>\n",
       "      <td>18</td>\n",
       "      <td>Kentucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>la</td>\n",
       "      <td>19</td>\n",
       "      <td>Louisiana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>me</td>\n",
       "      <td>20</td>\n",
       "      <td>Maine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>md</td>\n",
       "      <td>21</td>\n",
       "      <td>Maryland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ma</td>\n",
       "      <td>22</td>\n",
       "      <td>Massachusetts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mi</td>\n",
       "      <td>23</td>\n",
       "      <td>Michigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mn</td>\n",
       "      <td>24</td>\n",
       "      <td>Minnesota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ms</td>\n",
       "      <td>25</td>\n",
       "      <td>Mississippi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>mo</td>\n",
       "      <td>26</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mt</td>\n",
       "      <td>27</td>\n",
       "      <td>Montana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ne</td>\n",
       "      <td>28</td>\n",
       "      <td>Nebraska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>nv</td>\n",
       "      <td>29</td>\n",
       "      <td>Nevada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>nh</td>\n",
       "      <td>30</td>\n",
       "      <td>New Hampshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>nj</td>\n",
       "      <td>31</td>\n",
       "      <td>New Jersey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>nm</td>\n",
       "      <td>32</td>\n",
       "      <td>New Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ny</td>\n",
       "      <td>33</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>nc</td>\n",
       "      <td>34</td>\n",
       "      <td>North Carolina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>nd</td>\n",
       "      <td>35</td>\n",
       "      <td>North Dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>oh</td>\n",
       "      <td>36</td>\n",
       "      <td>Ohio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ok</td>\n",
       "      <td>37</td>\n",
       "      <td>Oklahoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>or</td>\n",
       "      <td>38</td>\n",
       "      <td>Oregon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>pa</td>\n",
       "      <td>39</td>\n",
       "      <td>Pennsylvania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ri</td>\n",
       "      <td>40</td>\n",
       "      <td>Rhode Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>sc</td>\n",
       "      <td>41</td>\n",
       "      <td>South Carolina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>sd</td>\n",
       "      <td>42</td>\n",
       "      <td>South Dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>tn</td>\n",
       "      <td>43</td>\n",
       "      <td>Tennessee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tx</td>\n",
       "      <td>44</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ut</td>\n",
       "      <td>45</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>vt</td>\n",
       "      <td>46</td>\n",
       "      <td>Vermont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>va</td>\n",
       "      <td>47</td>\n",
       "      <td>Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>wa</td>\n",
       "      <td>48</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>wv</td>\n",
       "      <td>49</td>\n",
       "      <td>West Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>wi</td>\n",
       "      <td>50</td>\n",
       "      <td>Wisconsin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>wy</td>\n",
       "      <td>51</td>\n",
       "      <td>Wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>oa</td>\n",
       "      <td>52</td>\n",
       "      <td>Other Areas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>us</td>\n",
       "      <td>53</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>cm</td>\n",
       "      <td>54</td>\n",
       "      <td>Total File, All States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   abbrev  id                    name\n",
       "0      al  01                 Alabama\n",
       "1      ak  02                  Alaska\n",
       "2      az  03                 Arizona\n",
       "3      ar  04                Arkansas\n",
       "4      ca  05              California\n",
       "5      co  06                Colorado\n",
       "6      ct  07             Connecticut\n",
       "7      de  08                Delaware\n",
       "8      dc  09    District of Columbia\n",
       "9      fl  10                 Florida\n",
       "10     ga  11                 Georgia\n",
       "11     hi  12                  Hawaii\n",
       "12     id  13                   Idaho\n",
       "13     il  14                Illinois\n",
       "14     in  15                 Indiana\n",
       "15     ia  16                    Iowa\n",
       "16     ks  17                  Kansas\n",
       "17     ky  18                Kentucky\n",
       "18     la  19               Louisiana\n",
       "19     me  20                   Maine\n",
       "20     md  21                Maryland\n",
       "21     ma  22           Massachusetts\n",
       "22     mi  23                Michigan\n",
       "23     mn  24               Minnesota\n",
       "24     ms  25             Mississippi\n",
       "25     mo  26                Missouri\n",
       "26     mt  27                 Montana\n",
       "27     ne  28                Nebraska\n",
       "28     nv  29                  Nevada\n",
       "29     nh  30           New Hampshire\n",
       "30     nj  31              New Jersey\n",
       "31     nm  32              New Mexico\n",
       "32     ny  33                New York\n",
       "33     nc  34          North Carolina\n",
       "34     nd  35            North Dakota\n",
       "35     oh  36                    Ohio\n",
       "36     ok  37                Oklahoma\n",
       "37     or  38                  Oregon\n",
       "38     pa  39            Pennsylvania\n",
       "39     ri  40            Rhode Island\n",
       "40     sc  41          South Carolina\n",
       "41     sd  42            South Dakota\n",
       "42     tn  43               Tennessee\n",
       "43     tx  44                   Texas\n",
       "44     ut  45                    Utah\n",
       "45     vt  46                 Vermont\n",
       "46     va  47                Virginia\n",
       "47     wa  48              Washington\n",
       "48     wv  49           West Virginia\n",
       "49     wi  50               Wisconsin\n",
       "50     wy  51                 Wyoming\n",
       "51     oa  52             Other Areas\n",
       "52     us  53           United States\n",
       "53     cm  54  Total File, All States"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compile structure for irs soi data\n",
    "# https://www.irs.gov/statistics/soi-tax-stats-historic-table-2\n",
    "\n",
    "import re\n",
    "import requests\n",
    "import requests_cache\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "requests_cache.install_cache()\n",
    "\n",
    "result = requests.get('https://www.irs.gov/statistics/soi-tax-stats-historic-table-2')\n",
    "assert result.status_code == 200\n",
    "c = result.content\n",
    "\n",
    "soup = BeautifulSoup(c)\n",
    "state_links = soup.find('table').find_all('a')\n",
    "\n",
    "state_refs = []\n",
    "\n",
    "for a in state_links:\n",
    "    state_dict = {}\n",
    "    \n",
    "    state_dict['name'] = a.string.strip()\n",
    "    \n",
    "    groups = re.search('\\d\\din(?P<id>\\d\\d)(?P<abbrev>\\w\\w)', a.attrs['href'])\n",
    "    state_dict.update(groups.groupdict())\n",
    "    \n",
    "    state_refs.append(state_dict)\n",
    "    \n",
    "df_state_refs = pd.DataFrame(state_refs).sort_values('id').reset_index(drop=True)\n",
    "\n",
    "display(df_state_refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dfs dict to store data we grab from the irs site\n",
    "CACHED_DFS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of functions that help us get soi_data from the web as a pandas dataframe\n",
    "# use: get_soi_df\n",
    "\n",
    "from requests import Session\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "class LiveServerSession(Session):\n",
    "    def __init__(self, prefix_url=None, *args, **kwargs):\n",
    "        super(LiveServerSession, self).__init__(*args, **kwargs)\n",
    "        self.prefix_url = prefix_url\n",
    "\n",
    "    def request(self, method, url, *args, **kwargs):\n",
    "        url = urljoin(self.prefix_url, url)\n",
    "        return super(LiveServerSession, self).request(method, url, *args, **kwargs)\n",
    "\n",
    "def lookup_state(key, val):\n",
    "    df = df_state_refs\n",
    "    condition = df[key] == val\n",
    "    state_info = df[condition].to_dict(orient='records')[0]\n",
    "    return state_info\n",
    "\n",
    "def get_soi_data(lookup, year):\n",
    "    state_info = lookup_state(*lookup)\n",
    "    filename = \"{}in{}{}\".format(\n",
    "        str(year)[2:],\n",
    "        state_info['id'],\n",
    "        state_info['abbrev']\n",
    "    )\n",
    "    pattern = r'{}\\.(xlsx?|zip)'.format(filename)\n",
    "    url = soup.find('a', href=re.compile(pattern)).attrs['href']\n",
    "    baseUrl = 'https://www.irs.gov'\n",
    "        \n",
    "    try:\n",
    "        with LiveServerSession(baseUrl) as s:\n",
    "            r = s.get(url)\n",
    "        assert r.status_code == 200\n",
    "    except:\n",
    "        raise\n",
    "        \n",
    "    return r\n",
    "\n",
    "def get_soi_df(lookup, year):\n",
    "    '''\n",
    "    get cumulative data as df given lookup and year\n",
    "    '''\n",
    "    from io import BytesIO\n",
    "    from zipfile import ZipFile\n",
    "    import itertools\n",
    "    \n",
    "    r = get_soi_data(lookup, year)\n",
    "    \n",
    "    print(r.url)\n",
    "    \n",
    "    if ((lookup, year) in CACHED_DFS):\n",
    "        return CACHED_DFS[(lookup, year)]\n",
    "    \n",
    "    pd_options = {\n",
    "        'header': None\n",
    "    }\n",
    "    \n",
    "    if '.xls' in r.url:\n",
    "        with BytesIO(r.content) as fh:\n",
    "            df = pd.read_excel(fh, **pd_options)\n",
    "    \n",
    "    elif '.zip' in r.url:\n",
    "        with ZipFile(BytesIO(r.content)) as my_zipfile:\n",
    "            for file in my_zipfile.namelist():\n",
    "                with my_zipfile.open(file) as fh:\n",
    "                    df = pd.read_excel(fh, **pd_options)\n",
    "    \n",
    "    CACHED_DFS[(lookup, year)] = df\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of functions that help us format soi dataframe\n",
    "# use: format_soi_df\n",
    "\n",
    "\n",
    "def rename_index(x):\n",
    "    try:\n",
    "        return x.strip().upper()\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "def get_indices(df):\n",
    "    from collections import defaultdict\n",
    "\n",
    "    iterator = df.iterrows()\n",
    "    indices = defaultdict(lambda: None)\n",
    "\n",
    "    while not np.all([indices[k] for k in ['place', 'amt']]):\n",
    "        idx, row = next(iterator)\n",
    "\n",
    "        if row.str.contains('alabama', flags=re.IGNORECASE).any() and not indices['place']:\n",
    "            indices['place'] = idx\n",
    "\n",
    "        if row.apply(str).str.contains('100,?000').any() and not indices['amt']:\n",
    "            indices['amt'] = idx\n",
    "\n",
    "    return dict(indices)\n",
    "\n",
    "def format_soi_df(df):\n",
    "    import numpy as np\n",
    "\n",
    "    my_df = df.copy()\n",
    "        \n",
    "    # identity target rows for indexing\n",
    "    indices = get_indices(my_df)\n",
    "\n",
    "    # fill null holes in columns for multiindexing\n",
    "    my_df.loc[indices['place']].fillna(method='ffill', inplace=True)\n",
    "    my_df.loc[indices['place']].fillna('', inplace=True)\n",
    "    my_df.loc[indices['place']] = my_df.loc[indices['place']].str.strip()\n",
    "    my_df.loc[indices['amt']].fillna('All returns', inplace=True)\n",
    "    \n",
    "    def format_column(x):\n",
    "        if isinstance(x, float) and np.isnan(x):\n",
    "            return x\n",
    "        elif isinstance(x, str) and 'Under' in x:\n",
    "            x = '0'\n",
    "        elif isinstance(x, str) and 'Breakeven' in x:\n",
    "            x = '0'\n",
    "        elif isinstance(x, str) and 'All' in x:\n",
    "            x = '-1'\n",
    "        else:\n",
    "            x = str(x)\n",
    "\n",
    "        try:\n",
    "            return float(x.split()[0].replace('$', '').replace(',', ''))\n",
    "        except:\n",
    "            return x.split()[0]\n",
    "\n",
    "    my_df.loc[indices['amt']] = my_df.loc[indices['amt']].apply(format_column)\n",
    "\n",
    "    # drop rows with any null values in arbitrary range â€“ we don't need these anymore\n",
    "    my_df = my_df[~my_df.iloc[:, 1:4].isnull().any(axis=1)]\n",
    "    \n",
    "    # get rid of footnotes in data\n",
    "    my_df.replace('\\s*\\[\\d+\\]', '', regex=True, inplace=True)\n",
    "\n",
    "    # set indices\n",
    "    my_df = my_df.transpose().set_index([*indices.values()])\n",
    "    my_df.index.set_names([*indices.keys()], inplace=True)\n",
    "    my_df.rename(index=rename_index, level='place', inplace=True)\n",
    "\n",
    "    # set columns\n",
    "    my_df.columns = my_df.iloc[0]\n",
    "    my_df = my_df.iloc[1:]\n",
    "    my_df.columns.rename('Item', inplace=True)\n",
    "    \n",
    "    # adjust alternate names\n",
    "    my_df.rename(columns={\n",
    "        'Returns Count': 'Number of returns'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    my_df = my_df[my_df.iloc[:, 3] != my_df.columns[3]] # drop rows that match header\n",
    "\n",
    "    return my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realign_tables unstacks IRS SOI csvs that organize the excel sheet in different\n",
    "# tables rather than just one wide one\n",
    "\n",
    "def realign_tables(df):    \n",
    "    # locate new stacked tables using the table heading\n",
    "    new_starts = df[df.iloc[:, 0].str.contains('^Table 2.', flags=re.IGNORECASE, na=False)].index\n",
    "    \n",
    "    # exception for older tables\n",
    "    if len(new_starts) == 0:\n",
    "        new_starts = df[df.iloc[:, 0].str.contains('^Tax Year 200', flags=re.IGNORECASE, na=False)].index\n",
    "    \n",
    "    # drop the first entry; it'll always be 0\n",
    "    new_starts = new_starts.drop(0)\n",
    "    \n",
    "    # if any entries besides the first...\n",
    "    if new_starts.any():\n",
    "        dfs = []\n",
    "        iterator = iter(new_starts.values)\n",
    "        \n",
    "        curr = 0\n",
    "                \n",
    "        for next_val in new_starts.values:\n",
    "            start = curr\n",
    "            curr = next_val\n",
    "            \n",
    "            dfs.append(df.loc[start:(curr-1), :].reset_index(drop=True))\n",
    "        \n",
    "        dfs.append(df.loc[curr:, :].reset_index(drop=True))\n",
    "        \n",
    "        concat = pd.concat(dfs, axis=1, ignore_index=True)\n",
    "        \n",
    "        # begone null columns\n",
    "        concat = concat.loc[:, ~concat.isnull().all()]\n",
    "        \n",
    "        return concat\n",
    "        \n",
    "    # ...else just return the data, no alignment needed    \n",
    "    else:\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cleaned_cm_df(year, do_print=False):\n",
    "    import datetime\n",
    "    import os\n",
    "    \n",
    "    \n",
    "    if do_print: print(datetime.datetime.now(), year, 'Fetching data')\n",
    "    df = get_soi_df(('abbrev', 'cm'), year)\n",
    "    if do_print: print(datetime.datetime.now(), year, 'Realigning data')\n",
    "    df = realign_tables(df)\n",
    "    if do_print: print(datetime.datetime.now(), year, 'Formatting data')\n",
    "    \n",
    "    if os.path.isfile(f'./working/{year}.csv'):\n",
    "        df = pd.read_csv(f'./working/{year}.csv', index_col=0, header=0)\n",
    "    \n",
    "    my_df = format_soi_df(df)\n",
    "    \n",
    "    return my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.irs.gov/pub/irs-soi/16in54cm.xlsx\n",
      "https://www.irs.gov/pub/irs-soi/15in54cm.xlsx\n",
      "https://www.irs.gov/pub/irs-soi/14in54cm.xlsx\n",
      "https://www.irs.gov/pub/irs-soi/13in54cm.xlsx\n",
      "https://www.irs.gov/pub/irs-soi/12in54cm.zip\n",
      "https://www.irs.gov/pub/irs-soi/11in54cm.zip\n",
      "https://www.irs.gov/pub/irs-soi/10in54cm.xls\n",
      "https://www.irs.gov/pub/irs-soi/09in54cm.xls\n",
      "https://www.irs.gov/pub/irs-soi/08in54cm.xls\n",
      "https://www.irs.gov/pub/irs-soi/07in54cm.xls\n",
      "https://www.irs.gov/pub/irs-soi/06in54cm.xls\n",
      "https://www.irs.gov/pub/irs-soi/05in54cm.xls\n",
      "https://www.irs.gov/pub/irs-soi/04in54cm.xls\n",
      "https://www.irs.gov/pub/irs-soi/03in54cm.xls\n",
      "https://www.irs.gov/pub/irs-soi/02in54cm.xls\n",
      "https://www.irs.gov/pub/irs-soi/01in54cm.xls\n",
      "https://www.irs.gov/pub/irs-soi/00in54cm.xls\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Number of returns</td>\n",
       "      <td>1/1/2016</td>\n",
       "      <td>il</td>\n",
       "      <td>Total</td>\n",
       "      <td>6100100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Number of returns</td>\n",
       "      <td>1/1/2016</td>\n",
       "      <td>il</td>\n",
       "      <td>Under $50k</td>\n",
       "      <td>3569220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Number of returns</td>\n",
       "      <td>1/1/2016</td>\n",
       "      <td>il</td>\n",
       "      <td>$50-$100k</td>\n",
       "      <td>1397680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Number of returns</td>\n",
       "      <td>1/1/2016</td>\n",
       "      <td>il</td>\n",
       "      <td>$100-$200k</td>\n",
       "      <td>827510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Number of returns</td>\n",
       "      <td>1/1/2016</td>\n",
       "      <td>il</td>\n",
       "      <td>$200k and greater</td>\n",
       "      <td>305690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1   2                  3        4\n",
       "0  Number of returns  1/1/2016  il              Total  6100100\n",
       "1  Number of returns  1/1/2016  il         Under $50k  3569220\n",
       "2  Number of returns  1/1/2016  il          $50-$100k  1397680\n",
       "3  Number of returns  1/1/2016  il         $100-$200k   827510\n",
       "4  Number of returns  1/1/2016  il  $200k and greater   305690"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "RANGES = {\n",
    "    'Total': (0,),\n",
    "    'Under $50k': (0, 5e4),     #    0 <= ... <  50k\n",
    "    '$50-$100k': (5e4, 1e5),    #  50k <= ... < 100k\n",
    "    '$100-$200k': (1e5, 2e5),   # 100k <= ... < 200k\n",
    "    '$200k and greater': (2e5,) # 200k <= ...\n",
    "}\n",
    "\n",
    "DIMENSIONS = [\n",
    "    'Number of returns',\n",
    "#     'Adjusted gross income (AGI)',\n",
    "]\n",
    "\n",
    "def build_query(my_place, lte, gt=None):\n",
    "    my_query = ''\n",
    "    \n",
    "    my_query += f'{lte} <= amt'\n",
    "    \n",
    "    if (gt):\n",
    "        my_query += f' < {gt} '\n",
    "    \n",
    "    my_query += f' and place == \"{my_place}\"'\n",
    "    \n",
    "    return my_query\n",
    "\n",
    "data = []\n",
    "\n",
    "def format_place(x):\n",
    "    df = df_state_refs[df_state_refs.name.str.contains(x, case=False)]\n",
    "    return df.abbrev.iloc[0]\n",
    "\n",
    "for year in range(2016, 1999, -1):\n",
    "    my_df = get_cleaned_cm_df(year)\n",
    "    my_place = \"Illinois\".upper()\n",
    "\n",
    "    for range_name, my_range in RANGES.items():\n",
    "        my_query = build_query(my_place, *my_range)\n",
    "        \n",
    "        for my_dimension in DIMENSIONS:\n",
    "            my_value = my_df.query(my_query)[my_dimension].astype('int64').sum()\n",
    "\n",
    "            data.append((\n",
    "                my_dimension,\n",
    "                f'1/1/{year}',\n",
    "                format_place(my_place),\n",
    "                range_name,\n",
    "                my_value\n",
    "            ))\n",
    "        \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ('dimension', 'date', 'group', 'range', 'val')\n",
    "\n",
    "pivot = pd.pivot_table(df, values='val', columns='range', index=['dimension', 'group', 'date'])\n",
    "\n",
    "pivot = pivot[['Under $50k', '$50-$100k', '$100-$200k', '$200k and greater']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjudge/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/pjudge/Library/Python/3.7/lib/python/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>range</th>\n",
       "      <th>Under $50k</th>\n",
       "      <th>$50-$100k</th>\n",
       "      <th>$100-$200k</th>\n",
       "      <th>$200k and greater</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimension</th>\n",
       "      <th>group</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"17\" valign=\"top\">Number of returns</th>\n",
       "      <th rowspan=\"17\" valign=\"top\">il</th>\n",
       "      <th>1/1/2000</th>\n",
       "      <td>3980066</td>\n",
       "      <td>1253148</td>\n",
       "      <td>410470</td>\n",
       "      <td>143288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/1/2001</th>\n",
       "      <td>3951561</td>\n",
       "      <td>1272520</td>\n",
       "      <td>420215</td>\n",
       "      <td>130819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/1/2002</th>\n",
       "      <td>3922761</td>\n",
       "      <td>1271560</td>\n",
       "      <td>416318</td>\n",
       "      <td>125439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/1/2003</th>\n",
       "      <td>3885585</td>\n",
       "      <td>1271678</td>\n",
       "      <td>433796</td>\n",
       "      <td>131696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/1/2004</th>\n",
       "      <td>3840048</td>\n",
       "      <td>1299017</td>\n",
       "      <td>473357</td>\n",
       "      <td>150467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/1/2005</th>\n",
       "      <td>3832554</td>\n",
       "      <td>1319905</td>\n",
       "      <td>513157</td>\n",
       "      <td>170577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/1/2006</th>\n",
       "      <td>3855445</td>\n",
       "      <td>1357931</td>\n",
       "      <td>572474</td>\n",
       "      <td>193844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/1/2007</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/1/2008</th>\n",
       "      <td>3865517</td>\n",
       "      <td>1390269</td>\n",
       "      <td>649579</td>\n",
       "      <td>207061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/1/2009</th>\n",
       "      <td>3849417</td>\n",
       "      <td>1345143</td>\n",
       "      <td>627582</td>\n",
       "      <td>186041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/1/2010</th>\n",
       "      <td>3834120</td>\n",
       "      <td>1358185</td>\n",
       "      <td>651227</td>\n",
       "      <td>200337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/1/2011</th>\n",
       "      <td>3860445</td>\n",
       "      <td>1358033</td>\n",
       "      <td>683830</td>\n",
       "      <td>219720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/1/2012</th>\n",
       "      <td>3754050</td>\n",
       "      <td>1359260</td>\n",
       "      <td>717840</td>\n",
       "      <td>245950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/1/2013</th>\n",
       "      <td>3721230</td>\n",
       "      <td>1370470</td>\n",
       "      <td>752490</td>\n",
       "      <td>256510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/1/2014</th>\n",
       "      <td>3671840</td>\n",
       "      <td>1386000</td>\n",
       "      <td>790340</td>\n",
       "      <td>282930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/1/2015</th>\n",
       "      <td>3638660</td>\n",
       "      <td>1399680</td>\n",
       "      <td>822510</td>\n",
       "      <td>301130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/1/2016</th>\n",
       "      <td>3569220</td>\n",
       "      <td>1397680</td>\n",
       "      <td>827510</td>\n",
       "      <td>305690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "range                            Under $50k $50-$100k $100-$200k  \\\n",
       "dimension         group date                                       \n",
       "Number of returns il    1/1/2000    3980066   1253148     410470   \n",
       "                        1/1/2001    3951561   1272520     420215   \n",
       "                        1/1/2002    3922761   1271560     416318   \n",
       "                        1/1/2003    3885585   1271678     433796   \n",
       "                        1/1/2004    3840048   1299017     473357   \n",
       "                        1/1/2005    3832554   1319905     513157   \n",
       "                        1/1/2006    3855445   1357931     572474   \n",
       "                        1/1/2007                                   \n",
       "                        1/1/2008    3865517   1390269     649579   \n",
       "                        1/1/2009    3849417   1345143     627582   \n",
       "                        1/1/2010    3834120   1358185     651227   \n",
       "                        1/1/2011    3860445   1358033     683830   \n",
       "                        1/1/2012    3754050   1359260     717840   \n",
       "                        1/1/2013    3721230   1370470     752490   \n",
       "                        1/1/2014    3671840   1386000     790340   \n",
       "                        1/1/2015    3638660   1399680     822510   \n",
       "                        1/1/2016    3569220   1397680     827510   \n",
       "\n",
       "range                            $200k and greater  \n",
       "dimension         group date                        \n",
       "Number of returns il    1/1/2000            143288  \n",
       "                        1/1/2001            130819  \n",
       "                        1/1/2002            125439  \n",
       "                        1/1/2003            131696  \n",
       "                        1/1/2004            150467  \n",
       "                        1/1/2005            170577  \n",
       "                        1/1/2006            193844  \n",
       "                        1/1/2007                    \n",
       "                        1/1/2008            207061  \n",
       "                        1/1/2009            186041  \n",
       "                        1/1/2010            200337  \n",
       "                        1/1/2011            219720  \n",
       "                        1/1/2012            245950  \n",
       "                        1/1/2013            256510  \n",
       "                        1/1/2014            282930  \n",
       "                        1/1/2015            301130  \n",
       "                        1/1/2016            305690  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = pivot.xs('1/1/2007', level='date', drop_level=False)\n",
    "subset[:] = ''\n",
    "pivot.update(subset)\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "scope = ['https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name('/Users/pjudge/.credentials/BGA Graphics-3edf4552f3a5.json', scope)\n",
    "\n",
    "gc = gspread.authorize(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
    "\n",
    "worksheet = gc.open_by_key('1-Ayjw4mhGHuoO7Igo_3ecCf6OI-zjytvc3jNDZnnEd0').worksheet('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blank_out_worksheet(worksheet):\n",
    "    \"\"\"\n",
    "    totally blank out worksheet\n",
    "    \"\"\"\n",
    "    from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
    "    \n",
    "    zeroed_df = get_as_dataframe(worksheet)\n",
    "    \n",
    "    # set vals to null\n",
    "    zeroed_df[:] = np.nan\n",
    "    \n",
    "    # set cols to null\n",
    "    zeroed_df.rename(columns=lambda x: np.nan, inplace=True)\n",
    "    \n",
    "    # set worksheet to blank dataframe\n",
    "    set_with_dataframe(worksheet, zeroed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     5786972\n",
       "1     5775115\n",
       "2     5736078\n",
       "3     5722755\n",
       "4     5762889\n",
       "5     5836193\n",
       "6     5979694\n",
       "7            \n",
       "8     6112426\n",
       "9     6008183\n",
       "10    6043869\n",
       "11    6122028\n",
       "12    6077100\n",
       "13    6100700\n",
       "14    6131110\n",
       "15    6161980\n",
       "16    6100100\n",
       "dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_df = pivot.reset_index().drop(['dimension', 'group'], 'columns')\n",
    "\n",
    "new_df['$50k and greater'] = new_df.loc[:, '$50-$100k':].sum(axis=1)\n",
    "\n",
    "new_df[['Under $50k', '$50k and greater']].sum(axis=1)\n",
    "\n",
    "# new_df = new_df[['date', 'Under $50k', '$50k and greater']]\n",
    "\n",
    "# blank_out_worksheet(worksheet)\n",
    "# set_with_dataframe(worksheet, new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
